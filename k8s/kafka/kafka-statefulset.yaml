# Kafka Cluster with KRaft Mode (No Zookeeper)
# 3-broker cluster with replication factor 3
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: shahin-grc
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/component: broker
spec:
  clusterIP: None
  ports:
  - name: client
    port: 9092
    targetPort: 9092
  - name: controller
    port: 9093
    targetPort: 9093
  selector:
    app.kubernetes.io/name: kafka
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: shahin-grc
  labels:
    app.kubernetes.io/name: kafka
spec:
  type: ClusterIP
  ports:
  - name: client
    port: 9092
    targetPort: 9092
  selector:
    app.kubernetes.io/name: kafka
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: shahin-grc
data:
  server.properties.template: |
    # KRaft mode settings
    process.roles=broker,controller
    controller.quorum.voters=0@kafka-0.kafka-headless:9093,1@kafka-1.kafka-headless:9093,2@kafka-2.kafka-headless:9093

    # Listeners
    listeners=PLAINTEXT://:9092,CONTROLLER://:9093
    inter.broker.listener.name=PLAINTEXT
    controller.listener.names=CONTROLLER
    listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT

    # Log configuration
    log.dirs=/var/lib/kafka/data
    num.partitions=3
    default.replication.factor=3
    min.insync.replicas=2

    # Performance tuning
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600

    # Topic settings
    auto.create.topics.enable=true
    delete.topic.enable=true

    # Log retention
    log.retention.hours=168
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000

    # Replication settings
    offsets.topic.replication.factor=3
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=2

  init-kafka.sh: |
    #!/bin/bash
    set -e

    # Extract node ID from pod name (kafka-0 -> 0, kafka-1 -> 1, etc)
    NODE_ID=${POD_NAME##*-}

    # Create config from template
    cp /etc/kafka/server.properties.template /var/lib/kafka/config/server.properties

    # Add dynamic settings
    echo "node.id=$NODE_ID" >> /var/lib/kafka/config/server.properties
    echo "advertised.listeners=PLAINTEXT://${POD_NAME}.kafka-headless:9092" >> /var/lib/kafka/config/server.properties

    # Check if cluster is already formatted
    if [ ! -f /var/lib/kafka/data/.cluster_id ]; then
      # Generate or use shared cluster ID
      if [ "$NODE_ID" = "0" ]; then
        CLUSTER_ID=$(kafka-storage.sh random-uuid)
        echo "$CLUSTER_ID" > /var/lib/kafka/data/.cluster_id
      else
        # Wait for cluster ID from node 0
        while [ ! -f /var/lib/kafka/data/.cluster_id ]; do
          echo "Waiting for cluster ID..."
          sleep 2
        done
        CLUSTER_ID=$(cat /var/lib/kafka/data/.cluster_id)
      fi

      # Format storage
      kafka-storage.sh format -t $CLUSTER_ID -c /var/lib/kafka/config/server.properties --ignore-formatted || true
    fi

    echo "Starting Kafka broker..."
    exec kafka-server-start.sh /var/lib/kafka/config/server.properties
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: shahin-grc
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/component: broker
spec:
  serviceName: kafka-headless
  replicas: 3
  podManagementPolicy: OrderedReady
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        app.kubernetes.io/component: broker
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9092"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: kafka
            topologyKey: kubernetes.io/hostname

      securityContext:
        fsGroup: 1000
        runAsUser: 1000
        runAsGroup: 1000

      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.5.0
        imagePullPolicy: IfNotPresent

        ports:
        - name: client
          containerPort: 9092
        - name: controller
          containerPort: 9093

        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx1G -Xms1G"
        - name: KAFKA_JMX_PORT
          value: "9999"
        - name: KAFKA_JMX_HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: status.podIP

        command:
        - /bin/bash
        - /etc/kafka/init-kafka.sh

        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 2Gi

        startupProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 30

        livenessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 5

        readinessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        - name: config
          mountPath: /etc/kafka
        - name: kafka-config-vol
          mountPath: /var/lib/kafka/config

      terminationGracePeriodSeconds: 120

      volumes:
      - name: config
        configMap:
          name: kafka-config
          defaultMode: 0755
      - name: kafka-config-vol
        emptyDir: {}

  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app.kubernetes.io/name: kafka
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: longhorn
      resources:
        requests:
          storage: 50Gi
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kafka-pdb
  namespace: shahin-grc
  labels:
    app.kubernetes.io/name: kafka
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
